{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 2: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task 2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task 2.2: An agent using evolved rules using ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "from random import random, choice, randint\n",
    "from copy import deepcopy\n",
    "from typing import Callable, Literal\n",
    "from dataclasses import dataclass, field\n",
    "from tqdm.notebook import trange\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# named tuple to indicate a possible Nim ply\n",
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    \"\"\"\n",
    "    Class implementing the Nim game.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        \"\"\"\n",
    "        Game constructor.\n",
    "\n",
    "        Args:\n",
    "            num_rows: number of rows (piles);\n",
    "            k: maximum number of objects you can nim from a row.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        \"\"\"\n",
    "        Update the game by performing a ply.\n",
    "\n",
    "        Args:\n",
    "            ply: ply to perform.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k, f\"{num_objects=}, {self._k=}\"\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(nim: Nim, strategy1: Callable[[Nim], Nimply], strategy2: Callable[[Nim], Nimply]) -> Literal[0, 1]:\n",
    "    \"\"\"\n",
    "    Play a Nim game using the given strategies.\n",
    "\n",
    "    Args:\n",
    "        nim: Nim game instance;\n",
    "        strategy1: Player 0 strategy;\n",
    "        strategy2: Player 1 strategy.\n",
    "\n",
    "    Returns:\n",
    "        player: the winning player.\n",
    "    \"\"\"\n",
    "    logging.getLogger().setLevel(logging.WARN)\n",
    "\n",
    "    strategy = (strategy1, strategy2)\n",
    "\n",
    "    logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        logging.info(f\"ply: player {player} plays {ply}, {nim_sum(nim)}\")\n",
    "        nim.nimming(ply)\n",
    "        logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    logging.info(f\"status: Player {player} won!\")\n",
    "\n",
    "    return player\n",
    "\n",
    "\n",
    "def play_games(\n",
    "    nim: Nim,\n",
    "    player: int,\n",
    "    player_strategy: Callable[[Nim], Nimply],\n",
    "    opponent_strategy: Callable[[Nim], Nimply],\n",
    "    n_matches: int,\n",
    ") -> list[int]:\n",
    "    \"\"\"\n",
    "    Play a given number of matches on a Nim game instance.\n",
    "\n",
    "    Args:\n",
    "        nim: Nim game instance;\n",
    "        player: choose if your strategy is played by the first or second player;\n",
    "        player_strategy: your player strategy;\n",
    "        opponent_strategy: your opponent strategy;\n",
    "        n_matches: number of matchers to play.\n",
    "\n",
    "    Returns:\n",
    "        List history of the winning players.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        play_game(deepcopy(nim), player_strategy, opponent_strategy)\n",
    "        if player == 0\n",
    "        else play_game(deepcopy(nim), opponent_strategy, player_strategy)\n",
    "        for _ in range(n_matches)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streak(player_strategy, opponent_strategy, n_matches):\n",
    "    \"\"\"\n",
    "    Play a given number of random matches between two strategies.\n",
    "\n",
    "    Args:\n",
    "        player_strategy: your player strategy;\n",
    "        opponent_strategy: your opponent strategy;\n",
    "        n_matches: number of matchers to play.\n",
    "\n",
    "    Returns:\n",
    "        ercentage of wins.\n",
    "    \"\"\"\n",
    "    wins = 0\n",
    "    for _ in range(n_matches):\n",
    "        random_size = randint(4, 10)\n",
    "        random_k = choice([None, None, *[randint(2, random_size * 2 + 1) for _ in range(2)]])\n",
    "        nim = Nim(random_size, random_k)\n",
    "        player = choice([0, 1])\n",
    "        wins += 1 if play_games(nim, player, player_strategy, opponent_strategy, 1)[0] == player else 0\n",
    "    return wins / n_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    Perform a completely random move.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        A ply is returned.\n",
    "    \"\"\"\n",
    "    row = choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = randint(1, state.rows[row] if state.k is None else min(state.rows[row], state.k))\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    Pick always the maximum possible number of the lowest row.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        A ply is returned.\n",
    "    \"\"\"\n",
    "    possible_moves = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1 if state.k is None else min(c + 1, state.k))\n",
    "    ]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    \"\"\"\n",
    "    Compute nim-sum value on a Nim game instance.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        The nim-sum value of the current game is returned.\n",
    "    \"\"\"\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def generate_all_plies(state: Nim) -> list[Nimply]:\n",
    "    \"\"\"\n",
    "    Generate all possible plies on the current game.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        A list of plies is returned.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        Nimply(r, o)\n",
    "        for r, c in enumerate(state.rows)\n",
    "        for o in range(1, c + 1 if state.k is None else min(c + 1, state.k))\n",
    "    ]\n",
    "\n",
    "\n",
    "def analize(state: Nim) -> dict:\n",
    "    \"\"\"\n",
    "    Given a Nim game instance, this function computes all the possible plies\n",
    "    and the corresponding nim-sum values.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        Plies and corresponding nim-sum values are returned as a dict.\n",
    "    \"\"\"\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in generate_all_plies(state):\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    If possible, this function returns a move which leads to a nim-sum value not equal to zero,\n",
    "    otherwise a random move among all the possible moves.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        A ply is returned.\n",
    "    \"\"\"\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    logging.debug(pformat(f\"{analysis['possible_moves']}\"))\n",
    "    ply = choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without considering the value of $k$, we can win in a Nim game if we always play a move in order to have a nim-sum value of $0$.\n",
    "\n",
    "At some point, we end up in a position that has only one row of size 2 or more. \\\n",
    "In such a position the nim-sum value is not equal to 0. To win we must reduce this to size 0 or 1, leaving an odd number of rows with size 1. From that point on, all moves are forced.\n",
    "\n",
    "_*Reference: https://en.wikipedia.org/wiki/Nim#Proof_of_the_winning_formula*_.\n",
    "\n",
    "The following function implements this winning strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_system(state: Nim) -> Nimply:\n",
    "    \"\"\"\n",
    "    This function implement an expert system which beats the strategies defined above.\n",
    "    Details on how to win are available at https://en.wikipedia.org/wiki/Nim#Proof_of_the_winning_formula.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        A ply is returned.\n",
    "    \"\"\"\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    not_zero_rows = len(state.rows) - state.rows.count(0)\n",
    "    one_count_rows = state.rows.count(1)\n",
    "    if one_count_rows == not_zero_rows - 1:\n",
    "        is_odd = (one_count_rows % 2) == 1\n",
    "        row, objects = [(row, objects) for row, objects in enumerate(state.rows) if objects > 1][0]\n",
    "        if is_odd:\n",
    "            return Nimply(row, objects if state.k is None else min(objects, state.k))\n",
    "        return Nimply(row, objects - 1 if state.k is None else min(objects - 1, state.k))\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    logging.debug(pformat(f\"{analysis['possible_moves']}\"))\n",
    "    ply = choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Strategy\n",
    "\n",
    "### Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our idea is to implement an adaptive strategy that learns how to play depending on the current game phase. \n",
    "\n",
    "Suppose that we have $3$ different phases:\n",
    "- _early game_;\n",
    "- _mid game_;\n",
    "- _end game_.\n",
    "\n",
    "We decide in which phase we are in based on the formula $n_\\textrm{phase} = \\dfrac{\\textrm{\\# remaining plies}}{\\textrm{\\# possible plies from the beginning}} \\in [0, 1]$.\n",
    " \n",
    "We define $t_1, t_2$, two thresholds learnt by the _ES_ strategy, that divide the interval $[0, 1]$ in three parts: $i_1 = [0, t_1)$, $i_2 = [t_1, t_2]$ and $i_3 = (t_2, 1]$. \\\n",
    "If $n_\\textrm{phase} \\in i_1$ we are in _early game_, $n_\\textrm{phase} \\in i_2$ we are in _mid game_, otherwise we are in _end game_.\n",
    "\n",
    "Each phase has its own set of weights. One weight is associated to one of the strategies defined above. The probability of picking a strategy for a ply is directly proportional to its weight value.\n",
    "\n",
    "The _ES_ algorithm learns which strategy is best to play in each phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase_ratio(state: Nim) -> float:\n",
    "    \"\"\"\n",
    "    Get the n_phase value.\n",
    "\n",
    "    Args:\n",
    "        state: Nim game instance.\n",
    "\n",
    "    Returns:\n",
    "        The n_phase value is returned.\n",
    "    \"\"\"\n",
    "    all_plys_new_game = len(generate_all_plies(Nim(len(state.rows), state.k)))\n",
    "    all_plys_current_game = len(generate_all_plies(state))\n",
    "    return all_plys_current_game / all_plys_new_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(init=False)\n",
    "class Individual:\n",
    "    \"\"\"\n",
    "    Class that represents an individual.\n",
    "    \"\"\"\n",
    "\n",
    "    strategies: list[Callable[[Nim], Nimply]]\n",
    "    strategy_weights: list[list[float]]\n",
    "    phase_thresholds: list[float]\n",
    "\n",
    "    def __init__(\n",
    "        self, strategies: int = None, strategy_weights: list[list[float]] = None, phase_thresholds: list[float] = None\n",
    "    ):\n",
    "        if strategies is None:\n",
    "            strategies = [pure_random, gabriele, optimal, expert_system]\n",
    "        if strategy_weights is None:\n",
    "            strategy_weights = np.random.randint(low=1, high=10, size=(3, len(strategies)))\n",
    "        if phase_thresholds is None:\n",
    "            phase_thresholds = sorted([random(), random()])\n",
    "        else:\n",
    "            phase_thresholds = sorted(phase_thresholds)\n",
    "\n",
    "        self.strategies = strategies\n",
    "        self.strategy_weights = strategy_weights\n",
    "        self.phase_thresholds = phase_thresholds\n",
    "\n",
    "    def _softmax(self, values) -> list[list[float]]:\n",
    "        tmp = np.exp(values)\n",
    "        return (tmp / np.sum(tmp)).tolist()\n",
    "\n",
    "    def mutate(ind: \"Individual\") -> \"Individual\":\n",
    "        global mutation_rate\n",
    "        strategy_weights = np.clip(np.random.normal(loc=ind.strategy_weights, scale=mutation_rate[0]), 1, 10).tolist()\n",
    "        phase_thresholds = np.clip(np.random.normal(loc=ind.phase_thresholds, scale=mutation_rate[1]), 0, 1).tolist()\n",
    "        return Individual(\n",
    "            strategies=ind.strategies, strategy_weights=strategy_weights, phase_thresholds=phase_thresholds\n",
    "        )\n",
    "\n",
    "    def __call__(self, state: Nim) -> Nimply:\n",
    "        phase_ratio = get_phase_ratio(state)\n",
    "        phase_index = (\n",
    "            0 if phase_ratio < self.phase_thresholds[0] else (2 if phase_ratio > self.phase_thresholds[1] else 1)\n",
    "        )\n",
    "        weights = self.strategy_weights[phase_index]\n",
    "        strategy = np.random.choice(self.strategies, p=self._softmax(weights))\n",
    "        return strategy(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 + $\\lambda$)-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 30\n",
    "N_MATCHES = 10\n",
    "N_ITERS = 1_000\n",
    "FACTOR = 1.5\n",
    "OPPONENT = expert_system\n",
    "mutation_rate: tuple[float] = (2.5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- First Individual\n",
      "Individual(strategies=[<function pure_random at 0x109a894e0>,\n",
      "                       <function gabriele at 0x109a896c0>,\n",
      "                       <function optimal at 0x109a89800>,\n",
      "                       <function expert_system at 0x109a898a0>],\n",
      "           strategy_weights=array([[3, 6, 8, 8],\n",
      "       [8, 1, 2, 6],\n",
      "       [8, 8, 3, 9]]),\n",
      "           phase_thresholds=[0.46903820024313614, 0.7188280047144948])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a30c9c3c0064e7c8d73c66a7654fcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best Individual\n",
      "Individual(strategies=[<function pure_random at 0x109a894e0>,\n",
      "                       <function gabriele at 0x109a896c0>,\n",
      "                       <function optimal at 0x109a89800>,\n",
      "                       <function expert_system at 0x109a898a0>],\n",
      "           strategy_weights=[[4.4186130102164345,\n",
      "                              3.14106918754073,\n",
      "                              3.613729594039401,\n",
      "                              9.996039924069041],\n",
      "                             [2.765247277444072,\n",
      "                              1.4815181759801608,\n",
      "                              2.9565777956431263,\n",
      "                              8.316687001063416],\n",
      "                             [5.030018689369344,\n",
      "                              10.0,\n",
      "                              4.326676846039679,\n",
      "                              4.542936608647975]],\n",
      "           phase_thresholds=[0.5398362109851288, 1.0])\n",
      "Best Individual Accuracy: 46.00%\n"
     ]
    }
   ],
   "source": [
    "parent = Individual()\n",
    "parent_result = streak(parent, OPPONENT, N_MATCHES)\n",
    "print('-- First Individual')\n",
    "pprint(parent)\n",
    "\n",
    "pbar = trange(0, N_ITERS // LAMBDA)\n",
    "for _ in pbar:\n",
    "    pbar.set_description(f'Parent Accuracy: {parent_result:.2%}')\n",
    "    offspring = [parent.mutate() for _ in range(LAMBDA)]\n",
    "    results = [streak(ind, OPPONENT, N_MATCHES) for ind in offspring]\n",
    "\n",
    "    if np.sum(np.array(results) > parent_result) / LAMBDA > 1 / 5:\n",
    "        mutation_rate = (mutation_rate[0] * FACTOR, mutation_rate[1] * FACTOR)\n",
    "    else:\n",
    "        mutation_rate = (mutation_rate[0] / FACTOR, mutation_rate[1] / FACTOR)\n",
    "\n",
    "    solution_index = np.argmax(results)\n",
    "    if parent_result < results[solution_index]:\n",
    "        parent = offspring[solution_index]\n",
    "        parent_result = results[solution_index]\n",
    "\n",
    "    if parent_result >= 0.999:\n",
    "        break\n",
    "\n",
    "best_plus = parent\n",
    "print('-- Best Individual')\n",
    "pprint(best_plus)\n",
    "print(f'Best Individual Accuracy: {streak(best_plus, OPPONENT, 100):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the best individual for the plus strategy\n",
    "with open('best_plus.pkl', 'wb') as f:\n",
    "    pickle.dump(best_plus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best individual for the plus strategy\n",
    "with open('best_plus.pkl', 'rb') as f:\n",
    "    best_plus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1, $\\lambda$)-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 30\n",
    "N_MATCHES = 10\n",
    "N_ITERS = 1_000\n",
    "FACTOR = 1.1\n",
    "OPPONENT = expert_system\n",
    "mutation_rate: tuple[float] = (1.5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- First Individual\n",
      "Individual(strategies=[<function pure_random at 0x109a894e0>,\n",
      "                       <function gabriele at 0x109a896c0>,\n",
      "                       <function optimal at 0x109a89800>,\n",
      "                       <function expert_system at 0x109a898a0>],\n",
      "           strategy_weights=array([[5, 6, 7, 2],\n",
      "       [3, 6, 7, 5],\n",
      "       [7, 1, 4, 5]]),\n",
      "           phase_thresholds=[0.28615992897279696, 0.33743931022473583])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0290ca8d0c66431da6f62908b5e7c0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Best Individual\n",
      "Individual(strategies=[<function pure_random at 0x109a894e0>,\n",
      "                       <function gabriele at 0x109a896c0>,\n",
      "                       <function optimal at 0x109a89800>,\n",
      "                       <function expert_system at 0x109a898a0>],\n",
      "           strategy_weights=[[3.0889994342396667,\n",
      "                              6.7601427417936595,\n",
      "                              4.777263698916828,\n",
      "                              1.1973202646743928],\n",
      "                             [5.498704729810203,\n",
      "                              5.497292084432263,\n",
      "                              1.903679679994468,\n",
      "                              10.0],\n",
      "                             [3.9647858584752957,\n",
      "                              2.0616940692904815,\n",
      "                              3.0956824908195477,\n",
      "                              10.0]],\n",
      "           phase_thresholds=[0.0, 0.5251936958805217])\n",
      "Best Individual Accuracy: 42.00%\n"
     ]
    }
   ],
   "source": [
    "parent = Individual()\n",
    "parent_result = streak(parent, OPPONENT, N_MATCHES)\n",
    "best_comma = parent\n",
    "best_comma_result = parent_result\n",
    "print('-- First Individual')\n",
    "pprint(parent)\n",
    "\n",
    "pbar = trange(0, N_ITERS // LAMBDA)\n",
    "for _ in pbar:\n",
    "    pbar.set_description(f'Parent Accuracy: {parent_result:.2%}')\n",
    "    offspring = [parent.mutate() for _ in range(LAMBDA)]\n",
    "    results = [streak(ind, OPPONENT, N_MATCHES) for ind in offspring]\n",
    "\n",
    "    if np.sum(np.array(results) > parent_result) / LAMBDA > 1 / 5:\n",
    "        mutation_rate = (mutation_rate[0] * FACTOR, mutation_rate[1] * FACTOR)\n",
    "    else:\n",
    "        mutation_rate = (mutation_rate[0] / FACTOR, mutation_rate[1] / FACTOR)\n",
    "\n",
    "    solution_index = np.argmax(results)\n",
    "    parent = offspring[solution_index]\n",
    "    parent_result = results[solution_index]\n",
    "\n",
    "    if best_comma_result < parent_result:\n",
    "        best_comma = parent\n",
    "        best_comma_result = parent_result\n",
    "\n",
    "    if parent_result >= 0.999:\n",
    "        break\n",
    "\n",
    "print('-- Best Individual')\n",
    "pprint(best_comma)\n",
    "print(f'Best Individual Accuracy: {streak(best_comma, OPPONENT, 100):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the best individual for the comma strategy\n",
    "with open('best_comma.pkl', 'wb') as f:\n",
    "    pickle.dump(best_comma, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best individual for the comma strategy\n",
    "with open('best_comma.pkl', 'rb') as f:\n",
    "    best_comma = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_strategy(\n",
    "    nim: Nim,\n",
    "    player: int,\n",
    "    player_strategy: Callable[[Nim], Nimply],\n",
    "    opponent_strategies: list[Callable[[Nim], Nimply]],\n",
    "    n_matches: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This function prints how many times the given player strategy\n",
    "    wins against the opponent strategies.\n",
    "\n",
    "    Args:\n",
    "        nim: Nim game instance;\n",
    "        player: which player to play;\n",
    "        player_strategy: which strategy to play;\n",
    "        opponent_strategies: which strategies to play against;\n",
    "        n_matches: number of matches to assess the quality of the strategy.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    for opponent_strategy in opponent_strategies:\n",
    "        games = play_games(nim, player, player_strategy, opponent_strategy, n_matches)\n",
    "        accuracy = games.count(player) / len(games)\n",
    "        print(\n",
    "            f\"-- Player {player} ({player_strategy.__qualname__}) against {opponent_strategy.__qualname__}: {accuracy:.2%} wins\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = Nim(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Player 0 (expert_system) against pure_random: 84.10% wins\n",
      "-- Player 0 (expert_system) against gabriele: 94.70% wins\n",
      "-- Player 0 (expert_system) against optimal: 92.80% wins\n"
     ]
    }
   ],
   "source": [
    "assess_strategy(\n",
    "    nim=nim,\n",
    "    player=0,\n",
    "    player_strategy=expert_system,\n",
    "    opponent_strategies=[pure_random, gabriele, optimal],\n",
    "    n_matches=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Player 1 (expert_system) against pure_random: 83.90% wins\n",
      "-- Player 1 (expert_system) against gabriele: 93.30% wins\n",
      "-- Player 1 (expert_system) against optimal: 91.60% wins\n"
     ]
    }
   ],
   "source": [
    "assess_strategy(\n",
    "    nim=nim,\n",
    "    player=1,\n",
    "    player_strategy=expert_system,\n",
    "    opponent_strategies=[pure_random, gabriele, optimal],\n",
    "    n_matches=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 + $\\lambda$)-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Player 0 (adaptive strategy (1 + 𝜆)-ES) against pure_random: 84.80% wins\n",
      "-- Player 0 (adaptive strategy (1 + 𝜆)-ES) against gabriele: 94.00% wins\n",
      "-- Player 0 (adaptive strategy (1 + 𝜆)-ES) against optimal: 91.80% wins\n",
      "-- Player 0 (adaptive strategy (1 + 𝜆)-ES) against expert_system: 56.20% wins\n"
     ]
    }
   ],
   "source": [
    "best_plus.__qualname__ = \"adaptive strategy (1 + 𝜆)-ES\"\n",
    "\n",
    "assess_strategy(\n",
    "    nim=nim,\n",
    "    player=0,\n",
    "    player_strategy=best_plus,\n",
    "    opponent_strategies=[pure_random, gabriele, optimal, expert_system],\n",
    "    n_matches=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Player 1 (adaptive strategy (1 + 𝜆)-ES) against pure_random: 84.40% wins\n",
      "-- Player 1 (adaptive strategy (1 + 𝜆)-ES) against gabriele: 92.60% wins\n",
      "-- Player 1 (adaptive strategy (1 + 𝜆)-ES) against optimal: 91.30% wins\n",
      "-- Player 1 (adaptive strategy (1 + 𝜆)-ES) against expert_system: 42.20% wins\n"
     ]
    }
   ],
   "source": [
    "best_plus.__qualname__ = \"adaptive strategy (1 + 𝜆)-ES\"\n",
    "\n",
    "assess_strategy(\n",
    "    nim=nim,\n",
    "    player=1,\n",
    "    player_strategy=best_plus,\n",
    "    opponent_strategies=[pure_random, gabriele, optimal, expert_system],\n",
    "    n_matches=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1, $\\lambda$)-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Player 0 (adaptive strategy (1, 𝜆)-ES) against pure_random: 81.80% wins\n",
      "-- Player 0 (adaptive strategy (1, 𝜆)-ES) against gabriele: 93.40% wins\n",
      "-- Player 0 (adaptive strategy (1, 𝜆)-ES) against optimal: 91.70% wins\n",
      "-- Player 0 (adaptive strategy (1, 𝜆)-ES) against expert_system: 56.50% wins\n"
     ]
    }
   ],
   "source": [
    "best_comma.__qualname__ = \"adaptive strategy (1, 𝜆)-ES\"\n",
    "\n",
    "assess_strategy(\n",
    "    nim=nim,\n",
    "    player=0,\n",
    "    player_strategy=best_comma,\n",
    "    opponent_strategies=[pure_random, gabriele, optimal, expert_system],\n",
    "    n_matches=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Player 1 (adaptive strategy (1, 𝜆)-ES) against pure_random: 83.30% wins\n",
      "-- Player 1 (adaptive strategy (1, 𝜆)-ES) against gabriele: 91.30% wins\n",
      "-- Player 1 (adaptive strategy (1, 𝜆)-ES) against optimal: 89.90% wins\n",
      "-- Player 1 (adaptive strategy (1, 𝜆)-ES) against expert_system: 42.70% wins\n"
     ]
    }
   ],
   "source": [
    "best_comma.__qualname__ = \"adaptive strategy (1, 𝜆)-ES\"\n",
    "\n",
    "assess_strategy(\n",
    "    nim=nim,\n",
    "    player=1,\n",
    "    player_strategy=best_comma,\n",
    "    opponent_strategies=[pure_random, gabriele, optimal, expert_system],\n",
    "    n_matches=1000,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
